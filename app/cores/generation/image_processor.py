"""Image processing utilities for generated images."""

import os
from datetime import datetime

import torch
from diffusers.pipelines.stable_diffusion.pipeline_output import StableDiffusionPipelineOutput
from PIL import Image

from app.services import logger_service
from config import GENERATED_IMAGES_FOLDER, GENERATED_IMAGES_STATIC_FOLDER

logger = logger_service.get_logger(__name__, category='Generate')


class ImageProcessor:
	"""Processes generated images: saving, NSFW detection, preview generation."""

	def __init__(self):
		"""Initialize ImageProcessor with cached weight tensors."""
		# Cache for weight tensors to avoid recreating them every time
		self.cached_weights = {}
		self.cached_biases = {}

		# Define the weight matrix (constant across all conversions)
		self.weights_data = (
			(60, -60, 25, -70),
			(60, -5, 15, -50),
			(60, 10, -5, -35),
		)
		self.biases_data = (150, 140, 130)

	def get_cached_tensors(self, device, dtype):
		"""Get or create cached weight/bias tensors for the given device and dtype.

		Args:
			device: torch.device to place tensors on
			dtype: torch.dtype for the tensors

		Returns:
			Tuple of (weights_tensor, biases_tensor)
		"""
		cache_key = (str(device), str(dtype))

		if cache_key not in self.cached_weights:
			with torch.no_grad():
				# Create and cache the tensors
				weights_tensor = torch.t(torch.tensor(self.weights_data, dtype=dtype).to(device))
				biases_tensor = torch.tensor(self.biases_data, dtype=dtype).to(device)

				self.cached_weights[cache_key] = weights_tensor
				self.cached_biases[cache_key] = biases_tensor

		return self.cached_weights[cache_key], self.cached_biases[cache_key]

	def clear_tensor_cache(self):
		"""Clear cached weight/bias tensors to free GPU memory."""
		with torch.no_grad():
			# Delete all cached tensors
			for tensor in self.cached_weights.values():
				del tensor
			for tensor in self.cached_biases.values():
				del tensor

			self.cached_weights.clear()
			self.cached_biases.clear()

			# Force GPU memory cleanup
			if torch.cuda.is_available():
				torch.cuda.empty_cache()

	def is_nsfw_content_detected(self, output: StableDiffusionPipelineOutput) -> list[bool]:
		"""Check if NSFW content was detected in the output.

		Args:
			output: Pipeline output from StableDiffusion containing images and NSFW detection results.

		Returns:
			List of boolean values indicating NSFW detection for each generated image.

		Note:
			SDXL models don't have NSFW detection, only SD 1.5 models do.
		"""
		# Check if NSFW detection is available (SD 1.5 models have it, SDXL models don't)
		nsfw_detected = getattr(output, 'nsfw_content_detected', None)

		if nsfw_detected is None:
			# NSFW detection not available (e.g., SDXL models)
			logger.info('NSFW detection not available for this model (likely SDXL)')
			return [False] * len(output.images)

		# Safety checker ran - check if ANY image contains NSFW content
		if any(nsfw_detected):
			nsfw_count = sum(nsfw_detected)
			logger.warning(f'NSFW content detected in {nsfw_count} of {len(nsfw_detected)} image(s)')
		else:
			logger.info('Safety checker: No NSFW content detected')

		return nsfw_detected

	def generate_file_name(self) -> str:
		"""Generate a unique file name based on the current timestamp.

		Returns:
			Unique filename string in format: YYYYMMDD_HHMMSS_microseconds
		"""
		return datetime.now().strftime('%Y%m%d_%H%M%S_%f')

	def save_image(self, image: Image.Image) -> tuple[str, str]:
		"""Save generated image to disk.

		Args:
			image: PIL Image to save.

		Returns:
			Tuple of (static_path, file_name) for the saved image.

		Raises:
			ValueError: If image is None or failed to generate.
		"""
		if not image:
			logger.error('No image was generated by the pipeline.')
			raise ValueError('Failed to generate any image.')

		file_name = self.generate_file_name()
		save_path = os.path.join(GENERATED_IMAGES_FOLDER, f'{file_name}.png')
		static_path = os.path.join(GENERATED_IMAGES_STATIC_FOLDER, f'{file_name}.png')

		image.save(save_path)

		logger.info(f'Generated image saved to: {save_path}')

		return static_path, file_name

	def latents_to_rgb(self, latents: torch.Tensor) -> Image.Image:
		"""Convert latents to RGB image for preview with efficient memory usage.

		Args:
			latents: Latent tensor from diffusion pipeline.

		Returns:
			PIL Image in RGB format.
		"""
		with torch.no_grad():  # Prevent gradient computation
			# Get cached tensors instead of creating new ones
			weights_tensor, biases_tensor = self.get_cached_tensors(latents.device, latents.dtype)

			# Compute RGB tensor
			rgb_tensor = torch.einsum('...lxy,lr -> ...rxy', latents, weights_tensor) + biases_tensor.unsqueeze(-1).unsqueeze(
				-1
			)

			# Move to CPU with explicit detach to break computation graph
			image_array = rgb_tensor.clamp(0, 255).byte().detach().cpu().numpy().transpose(1, 2, 0)

			# Only delete the intermediate tensor, not the cached ones
			del rgb_tensor

		return Image.fromarray(image_array)


image_processor = ImageProcessor()
