"""Image processing utilities for generated images."""

import logging
import os
from datetime import datetime

import torch
from PIL import Image

from config import GENERATED_IMAGES_FOLDER, GENERATED_IMAGES_STATIC_FOLDER

logger = logging.getLogger(__name__)


class ImageProcessor:
	"""Processes generated images: saving, NSFW detection, preview generation."""

	def is_nsfw_content_detected(self, output) -> list[bool]:
		"""Check if NSFW content was detected in the output.

		Args:
			output: Pipeline output dictionary containing 'nsfw_content_detected' key.

		Returns:
			List of boolean values indicating NSFW detection for each generated image.
		"""
		logger.info(f'Checking for NSFW content: {output.get("nsfw_content_detected")}')

		if output.get('nsfw_content_detected'):
			logger.warning('NSFW content detected')
			return output.get('nsfw_content_detected')

		return [False] * len(output.get('images', []))

	def generate_file_name(self) -> str:
		"""Generate a unique file name based on the current timestamp.

		Returns:
			Unique filename string in format: YYYYMMDD_HHMMSS_microseconds
		"""
		return datetime.now().strftime('%Y%m%d_%H%M%S_%f')

	def save_image(self, image: Image.Image) -> tuple[str, str]:
		"""Save generated image to disk.

		Args:
			image: PIL Image to save.

		Returns:
			Tuple of (static_path, file_name) for the saved image.

		Raises:
			ValueError: If image is None or failed to generate.
		"""
		if not image:
			logger.error('No image was generated by the pipeline.')
			raise ValueError('Failed to generate any image.')

		file_name = self.generate_file_name()
		save_path = os.path.join(GENERATED_IMAGES_FOLDER, f'{file_name}.png')
		static_path = os.path.join(GENERATED_IMAGES_STATIC_FOLDER, f'{file_name}.png')

		image.save(save_path)

		logger.info(f'Generated image saved to: {save_path}')

		return static_path, file_name

	def latents_to_rgb(self, latents: torch.Tensor) -> Image.Image:
		"""Convert latents to RGB image for preview.

		Args:
			latents: Latent tensor from diffusion pipeline.

		Returns:
			PIL Image in RGB format.
		"""
		weights = (
			(60, -60, 25, -70),
			(60, -5, 15, -50),
			(60, 10, -5, -35),
		)

		weights_tensor = torch.t(torch.tensor(weights, dtype=latents.dtype).to(latents.device))
		biases_tensor = torch.tensor((150, 140, 130), dtype=latents.dtype).to(latents.device)
		rgb_tensor = torch.einsum('...lxy,lr -> ...rxy', latents, weights_tensor) + biases_tensor.unsqueeze(-1).unsqueeze(
			-1
		)
		image_array = rgb_tensor.clamp(0, 255).byte().cpu().numpy().transpose(1, 2, 0)

		return Image.fromarray(image_array)


image_processor = ImageProcessor()
